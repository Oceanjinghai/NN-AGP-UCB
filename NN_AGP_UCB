import numpy as np
import pandas as pd
import scipy.sparse as sp
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from tqdm.notebook import tnrange,tqdm
import gpytorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import math
import numpy as np
import torch.optim as optim
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import pyplot as plt
import GPy
from torch import nn
import itertools

import torch
import numpy as np
import torch.optim as optim
import gpytorch
import scipy.sparse as sp
# Assuming GraphNet and network are properly imported and are secure and reliable modules.
# With An example type of code with network experiment


class NN_AGP_UCB:
    def __init__(self, actions, contexts, sample_from_environment, learning_rate=1.0):
        """
        Initialize the Neural Network with Contextual Gaussian Process Upper Confidence Bound.
        
        Parameters should be validated before being passed here to ensure they meet the required criteria 
        (e.g., correct types, acceptable values) to prevent type confusion, unexpected behavior, or data corruption.
        """

        # It's crucial to validate the inputs, ensuring they adhere to the expected format, 
        # especially if they're coming from untrusted sources or user input.
        if not isinstance(actions, np.ndarray) or not isinstance(contexts, np.ndarray):
            raise TypeError("Actions and contexts must be NumPy arrays.")
        if not callable(sample_from_environment):
            raise TypeError("sample_from_environment must be a callable function.")

        # Initialize internal state
        # If there are default values or configurations, they should be set in a manner that reduces risks.
        # Avoid using insecure or unpredictable states.
        # Consider setting safe defaults if applicable.
        self.learning_rate = learning_rate
        self.actions = torch.Tensor(actions).cuda()
        self.contexts = torch.Tensor(contexts).cuda()

        # More initializations...
        # Ensure that all initializations are done securely, without exposing sensitive data.
        # Verify that the operations cannot be tampered with to compromise the system.

        # For all components that require secure initialization, consider:
        # - Secure random number generation where needed
        # - Checks to ensure configurations haven't been tampered with
        # - Using secure computation methods if handling sensitive data

        self.K = gpytorch.kernels.RBFKernel(ard_num_dims=self.action_shape).cuda()
        self.sigma = torch.randn(1, requires_grad=True, device='cuda')
        self.g_function = GraphNet().cuda()

        # Securely manage parameters, especially if they could impact security controls.
        self.parameters = list(self.K.parameters()) + list(self.g_function.parameters())
        self.parameters.append(self.sigma)

        # Make sure the optimizer is initialized in a way that's consistent with your security policies.
        self.optim = optim.Adam(self.parameters, lr=self.learning_rate, eps=0.95)

        # Initialize other attributes securely...

    def collect(self, rounds=3):
        """
        Collect data samples. This method should handle errors gracefully, possibly logging them for future analysis.
        Ensure the rounds parameter can't be tampered with to cause potential Denial-of-Service (DoS) by overloading the system.
        """
        if not isinstance(rounds, int) or rounds <= 0:
            raise ValueError("Rounds must be a positive integer.")

        for _ in range(rounds):
            try:
                # Securely select a context index and an action. Ensure the randomness is unpredictable and secure.
                # Check for potential overflow or underflow in calculations.
                context_index = np.random.randint(self.context_num)
                action_index = np.random.randint(self.number_of_actions_in_each_context)

                # Secure sampling from the environment. The function should be robust against potential manipulation or errors.
                x = self.actions[action_index]
                theta = self.contexts[context_index]
                y = self.sample_from_environment(x.cpu().numpy(), theta.cpu().numpy())

                # Append data, ensuring that no buffer overflow can occur.
                self.X.append(x)
                self.Theta.append(theta)
                self.Y.append(torch.Tensor([y]).cuda())

            except Exception as e:
                # Log and handle exceptions securely. Sensitive information should not be exposed in error messages.
                # Consider a mechanism to alert or log for continuous monitoring and incident response.
                print(f"An error occurred: {str(e)}")  # For a real scenario, consider logging instead of printing.

    # Define other methods, ensuring:
    # - Secure handling of internal state changes
    # - Using secure functions for calculations, especially if overflow, underflow, or precision issues can occur
    # - Validating inputs and outputs
    # - Catching and handling exceptions securely
    # - Avoiding the exposure of sensitive information in errors or logs
    # - Sanitizing data used in interactions with external systems
    # - Ensuring thread safety if applicable
    # - Avoiding or securely managing the use of shared resources or state

def rule_and_update(self, context_index):
    """
    Update rule and choose the next action based on the updated information.

    :param context_index: Index of the context to be processed.
    """
    # Input validation: Check if context_index is an integer and within a valid range.
    if not isinstance(context_index, int) or not (0 <= context_index < self.context_num):
        raise ValueError("context_index must be an integer within the range of available contexts.")

    # Prepare for processing and handle exceptions for robustness.
    try:
        # Initialization and secure random number generation.
        sigma_list = []

        # Secure data processing: Ensure that data retrieval and manipulation are handled securely without
        # overflow or underflow, and with consideration for data integrity.
        theta = self.contexts[context_index].clone().detach()
        
        # Convert theta to the appropriate format securely.
        processed_theta = self.process_to_graph(theta)
        
        # Secure computation: Ensure that mathematical computations are accurate and prevent potential issues
        # like division by zero, overflow, or underflow.
        # Here, balance is created securely, preventing tampering and ensuring integrity.
        balance = torch.eye(len(self.X), device='cuda')

        # Secure matrix operations: Perform operations in a way that ensures data integrity and confidentiality.
        # Protect against potential vulnerabilities in these operations.
        self.Centre_matrix = (self.g_function(processed_theta) * self.K(torch.stack(self.X), torch.stack(self.X)) * 
                              self.g_function(torch.stack(self.Theta)).T)
        self.Centre_matrix += self.sigma**2 * balance

        # ... Additional secure operations ...

        # Compute mu securely and robustly, handling any exceptions that might occur.
        mu = torch.matmul(K_x_theta @ torch.inverse(self.Centre_matrix), torch.Tensor(self.Y))

        # Securely calculate sigma and mu, ensuring the integrity and confidentiality of the process.
        for i in range(self.number_of_actions_in_each_context):
            # ... secure computation of temp_sigma ...

            sigma_list.append(torch.sqrt(temp_sigma).item())  # Converting securely to Python scalar

        # Choose the next action securely and reliably.
        selected_arm_index = np.argmax(mu.cpu().numpy() + self.optimal_beta_selection(self.round, self.input_space_size, 0.8) * np.array(sigma_list))

        # Securely sample from the environment and update the state.
        x = self.actions[selected_arm_index]
        y = self.sample_from_environment(x, theta)

        # Securely update the parameters with robust exception handling.
        self.optim.zero_grad()

        for rep in range(200):
            # ... operations with self.Centre_matrix and loss computation ...

            loss.backward()
            self.optim.step()
            self.optim.zero_grad()
            
            # Secure logging: Ensure that logging is informative for monitoring purposes but doesn't leak sensitive information.
            print(f'loss for t={len(self.X)}: {loss.item()}')  # Use item() for scalar value

        # Securely update the system state, ensuring the integrity and consistency of the data.
        self.X.append(x)
        self.Theta.append(processed_theta)
        self.Y.append(torch.Tensor([y]).cuda())  # Ensure proper handling of tensor data

        self.round += 1

        return selected_arm_index

    except Exception as e:
        # Secure error handling: Log the error and handle it gracefully without exposing sensitive system information.
        print(f"An error occurred during rule_and_update: {str(e)}")  # Consider using logging in real scenarios
        # Implement appropriate error recovery or system alerting mechanisms here.

    # Additional security considerations might include secure memory management, avoiding race conditions,
    # and ensuring the secure deletion of sensitive data after use.
# Additional methods should be audited for security issues, ensuring that they adhere to best practices for secure coding.



class network():

    def __init__(self, params):
        if params['is_network_given']:
            self.mat_adj = params['given_network']
            self.n = self.mat_adj.shape[0]
        else:
            self.n = int(params['network_size'])
            self.p = float(params['edge_prob'])
            self.generate_random_network()

        #print(f'Instance generated with {self.n} nodes.')

        self.n_in = np.sum(self.mat_adj, axis=0)  # in-neighbor
        self.n_out = np.sum(self.mat_adj, axis=1)  # out-neighbor
        self.n_min = np.min(self.n_in)
        self.n_in[self.n_in == 0] = 1  # adjusted in-neighbor
        self.list_adj = [np.where(i > 0)[0] for i in self.mat_adj.T]
        self.list_adj_out = [np.where(i > 0)[0] for i in self.mat_adj]

        self.y = torch.zeros(self.n)  # adoption status

#         if params['is_value_given']:
#             self.value_dir = params['value']
#             self.read_value_from_csv()
#         else:
        self.v_dist_param = 4
        self.generate_random_value()

    def read_network_from_csv(self):
        # columns: ['from_node', 'to_node']
        self.df_edge = pd.read_csv(self.network_dir)
        l_edge = self.df_edge.values

        self.n = np.max(l_edge) + 1
        self.l_node = np.arange(0,self.n,1)

        mat_adj = np.zeros((self.n, self.n))
        mat_adj[tuple(l_edge.T)] = 1
        np.fill_diagonal(mat_adj, 0)
        self.mat_adj = mat_adj.astype('float32')

    # generate network according to some rules
    def generate_random_network(self):
        self.l_node = np.arange(0,self.n,1)
        mat_adj = (np.random.rand(self.n, self.n) < self.p).astype(int)
        np.fill_diagonal(mat_adj, 0)
        self.mat_adj = mat_adj
        self.generate_edge_from_mat()
    
    def generate_edge_from_mat(self):
        l_edge = np.where(self.mat_adj==1)
        self.df_edge = pd.DataFrame({'from_node': l_edge[0], 'to_node': l_edge[1]})

    def generate_random_value(self):
        self.v = np.random.uniform(0, self.v_dist_param, self.n)
        self.df_v = pd.DataFrame({'v':self.v})

    def read_value_from_csv(self):
        # columns: ['v']
        self.df_v = pd.read_csv(self.value_dir)
        self.v = self.df_v['v'].values.astype('float32')

    def reset(self):
        self.y = np.zeros(self.n)
        
    def update_network_structure(self):
        # you may want to call this function to change network structure
        # I think for this simple experiment, you can just regenerate a new random network,
        # although it may not be the case in reality.
        # If can change this part to whatever you like.
        self.generate_random_network()







THRESH = 1e-5

class grad():

    def __init__(self, sim, params):
        self.sim = sim
        self.lr_mu, self.lr_p = 1e-3, 1e-3 #these are learning rate, you may change it base your own experience
        self.W = params['W']
        self.K = params['K']
        self.alpha = self.sim.alpha

    def solve_mu_grad(self):
        lr = self.lr_mu
        v, n_in = self.sim.network_G.v, self.sim.network_G.n_in
        beta = self.sim.beta
        mu = np.ones(self.sim.network_G.n)*0.5

        last_mu = np.ones(self.sim.network_G.n)-THRESH
        last_profit = 0

        while np.linalg.norm(mu-last_mu,np.inf)>1e-5:
            last_mu = mu
            y_neighbor_mu = np.array([mu[i].sum() for i in self.sim.network_G.list_adj])
            y_neighbor_mu_inv = np.array([(mu[i]/n_in[i]).sum() for i in self.sim.network_G.list_adj_out])
            grad_mu = (v + beta*y_neighbor_mu/n_in + np.log((1-mu)/mu) -mu/(1-mu)-1 + beta*y_neighbor_mu_inv)/self.alpha

            mu = mu+grad_mu*lr
            mu[mu<=0] = THRESH
            mu[mu>=1] = 1-THRESH

            p = (v + beta * y_neighbor_mu / n_in + np.log((1 - mu) / mu))/self.alpha
            if np.sum(mu*p)<last_profit:
                lr = lr/2
            last_profit = np.sum(mu*p)

        self.mu = mu
        y_neighbor_mu = np.array([self.mu[i].sum() for i in self.sim.network_G.list_adj])
        self.p = (v + beta * y_neighbor_mu / n_in + np.log((1 - self.mu) / self.mu)) / self.alpha
        
    def solve_p_grad(self,start_pos,ub):
        lr = self.lr_p
        v, n_in = self.sim.network_G.v, self.sim.network_G.n_in
        beta = self.sim.beta

        p = start_pos
        p_user = self.W @ p
        mu = self.sim.run_fixed_point(self.alpha*p_user)

        last_p = -np.ones(self.K)
        last_profit = 0
        while np.linalg.norm(p-last_p,np.inf)>1e-2:
            last_p = p
            y_neighbor_mu = np.array([mu[i].sum() for i in self.sim.network_G.list_adj])
            exp = np.exp(-v - beta * y_neighbor_mu / n_in+self.alpha*p_user)
            part_h_p = - self.alpha * self.W.T * (exp / (1+exp)**2).T
            part_h_mu = self.sim.network_G.mat_adj * (exp / (1+exp)**2 * beta/n_in).T

            inv = np.identity(self.sim.network_G.n) + part_h_mu + part_h_mu@part_h_mu
            grad_pi_p = part_h_p @ inv @ self.W @ p + self.W.T @ mu
            p = p + grad_pi_p * lr
            p[p < 0] = 0
            p[p > ub] = ub[p>ub]
            p_user = self.W @ p
            mu = self.sim.run_fixed_point(self.alpha*p_user)

            if np.sum(mu*p_user)<last_profit:
                lr = lr/2
            last_profit = np.sum(mu*p_user)
        self.p = p[0]




class NN_AGP_UCB(object):

    def __init__(self, actions, contexts, sample_from_environment,learning_rate):

.

        # the dimension of actions
        self.learning_rate=1
        self.f_size = 1
        self.actions = torch.Tensor(actions)
        self.actions.to('cuda')
        self.contexts = torch.Tensor(contexts)
        self.contexts.to('cuda')
        self.action_shape = actions.shape[1]
        self.context_size = contexts.shape[1]
        self.context_num = contexts.shape[0]
        self.Centre_matrix = None
        # create action-context pairs via a meshgrid.
        self.input_mesh = np.array(np.meshgrid(actions.cpu(), contexts.cpu()))
        # number of actions in each context. currently only supports equal number of actions for each context.
        self.number_of_actions_in_each_context = np.size(self.input_mesh, 2)
        # sample from environment
        self.sample_from_environment = sample_from_environment
        self.beta = None
        self.K = gpytorch.kernels.RBFKernel(ard_num_dims=self.action_shape)
        self.K.cuda()
        self.sigma = torch.randn(1, requires_grad=True,device='cuda')
        self.g_function=GraphNet()
        self.g_function.cuda()
        
        self.parameters=list(self.K.parameters())+list(self.g_function.parameters())
        self.parameters.append(self.sigma)
        self.optim = optim.Adam(self.parameters, lr=self.learning_rate,eps=0.95)


        self.input_space = self.input_mesh.reshape(self.input_mesh.shape[0], -1).T
        self.input_space_size = self.input_space.size
        


        self.X = []
        self.Y = []
        self.Theta = []
        self.round = 1
        return


    def collect(self, rounds=3):

        for i in range(rounds):

            context_index = int(np.floor(np.random.rand()*self.context_num))    

            theta= self.contexts[context_index]

            x = self.actions[int(np.floor(np.random.rand()*self.number_of_actions_in_each_context))]

            y = self.sample_from_environment(x, theta)

            self.X.append(x.to('cuda'))

            self.Theta.append(theta.to('cuda'))

            self.Y.append(torch.Tensor(y).to('cuda'))   

        return
        
        
    def process_to_graph(self, theta):
        
        param_network = {'is_network_given': True, 'network_size': 3, 'edge_prob': 0.5, 'is_value_given': True, 'given_network': theta.reshape(3,3)}
        G = network(param_network)
        edge_index_temp = sp.coo_matrix(G.mat_adj)
        values = edge_index_temp.data  # extract weight
        indices = np.vstack((edge_index_temp.row, edge_index_temp.col))  # turn to coo matrix type
        edge_index_A = torch.LongTensor(indices).cuda()  # exact coo type in torch format
        i = torch.LongTensor(indices)  # turn to tensor
        v = torch.FloatTensor(values).cuda()  # turn to tensor

        return torch.Tensor([G.v,edge_index_A,v]) 

    def rule_and_update (self, context_index):
        
        
        sigma_list=[]
        
        context = int(context_index)

        theta=self.contexts[context_index]

        
        processed_theta = process_to_graph(theta_tensor)
        
        #theta_tensor=theta.view(1,-1).to('cuda')
        
        balance =torch.eye(len(self.X),device='cuda')

        self.Centre_matrix=torch.mul(torch.mul(self.g_function(processed_theta), self.K(torch.stack(self.X).to('cuda'),torch.stack(self.X).to('cuda'))), self.g_function(torch.stack(self.Theta)).T) 
        self.Centre_matrix.cuda()
        self.Centre_matrix+=self.sigma**2*balance
        
        self.Centre_matrix= self.Centre_matrix.to_dense()
        
        K_x_theta = self.g_function(processed_theta)*torch.mul(self.K(self.actions.to('cuda'),torch.Tensor(self.X).to('cuda')).to_dense(),self.g_function(torch.stack(self.Theta)).T).to_dense()
        
        mu = torch.matmul(K_x_theta.to('cuda')@ torch.inverse(self.Centre_matrix).to('cuda'), torch.Tensor(torch.Tensor(self.Y)).to('cuda'))
        
        
        for i in range(self.number_of_actions_in_each_context):
            
            
            K_x_temp=self.g_function(processed_theta)*torch.mul(self.K(self.actions[i].to('cuda'),torch.Tensor(self.X).to('cuda')).to_dense(),self.g_function(torch.stack(self.Theta)).T).to_dense()
            
            
            temp_sigma = torch.mul(torch.mul(self.g_function(processed_theta),self.K(self.actions[i].to('cuda'),self.actions[i].to('cuda')).to_dense()), self.g_function(processed_theta))- torch.matmul(K_x_temp.to('cuda')@ torch.inverse(self.Centre_matrix).to('cuda'), K_x_temp.to('cuda').T)
            
            
            sigma_list.append(torch.sqrt(temp_sigma).cpu().detach().numpy()[0][0])
        

        selected_arm_index = np.argmax(mu.cpu().detach().numpy()+ self.optimal_beta_selection(self.round,self.input_space_size,0.8)*np.array(sigma_list))
        
        x = self.actions[selected_arm_index]

        y = self.sample_from_environment(x, theta)
        
        self.optim.zero_grad()
        
        for rep in range(200):  
            
            self.Centre_matrix=torch.mul(torch.mul(self.g_function(processed_theta), self.K(torch.stack(self.X),torch.stack(self.X))), self.g_function(torch.stack(self.Theta)).T) +self.sigma.to('cuda')**2*torch.eye(len(self.X)).to('cuda')
        
            self.Centre_matrix= self.Centre_matrix.to_dense()
        
            loss=  torch.matmul(torch.matmul(torch.stack(self.Y).T, torch.inverse(self.Centre_matrix)),torch.stack(self.Y)) #+ torch.logdet(self.Centre_matrix)

            loss.backward()

            self.optim.step()
            
            self.optim.zero_grad()
            
        print('loss for t={}: {}'.format(len(self.X),loss))

                

        
        self.X.append(x.to('cuda'))

        self.Theta.append(processed_theta)

        self.Y.append(torch.Tensor(y).to('cuda'))  
        
        self.round += 1

        

        return selected_arm_index
